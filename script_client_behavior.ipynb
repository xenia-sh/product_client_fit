{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing, ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.cm as cm\n",
    " \n",
    "from sklearn import datasets, linear_model, metrics\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "#imported everything necessary\n",
    " \n",
    "dataset=pd.read_csv('C:/Users/xshitova/Documents/anon_file2.csv', delimiter=';')\n",
    "#importing the dataset as usual\n",
    " \n",
    "cols=[\"numerical_feature1\",\n",
    "      \"numerical_feature2\",\n",
    "      \"numerical_feature3\",\n",
    "      \"category_feature1\",\n",
    "      \"category_feature2\",\n",
    "      \"category_feature3\",\n",
    "      \"category_feature4\",\n",
    "      \"numerical_feature4\",\n",
    "      \"numerical_feature5\",\n",
    "      \"numerical_feature6\",\n",
    "      \"numerical_feature7\",\n",
    "  \t\"numerical_feature8\",\n",
    "      \"numerical_feature9\",\n",
    "      \"numerical_feature10\"]\n",
    "#explanatory variables (everything except client id)\n",
    " \n",
    "target=['target_variable']\n",
    "#this is the predicted variable\n",
    " \n",
    "dataset.dropna()#dropping empty values for now\n",
    "dataset = dataset[pd.notnull(dataset['category_feature1'])] #excluding lines where there is no category_feature1\n",
    "dataset = dataset[pd.notnull(dataset['category_feature2'])]\n",
    "dataset = dataset[pd.notnull(dataset['category_feature3'])]\n",
    "dataset = dataset[pd.notnull(dataset['category_feature4'])]\n",
    "dataset = dataset[pd.notnull(dataset['numerical_feature4'])]\n",
    "dataset = dataset[pd.notnull(dataset['numerical_feature8'])]\n",
    "#same for all the other indicators - conseautively drop values which are na\n",
    " \n",
    "for i in range(0,12):\n",
    "\tprint([cols[i]])\n",
    "    print(dataset[cols[i]].isnull().sum())\n",
    "    print(dataset[cols[i]].count())\n",
    "\t#until everything is 0 (meaning there are no nan values in any of columns)\n",
    "\t#197676 lines left\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[cols], dataset[target], test_size = 0.3, random_state=42)\n",
    "#the train test split as I haven't used it before - done manually instead\n",
    " \n",
    "print(\"Random forest model\")\n",
    "random_forest1 = RandomForestClassifier()\n",
    "random_forest1.fit(X_train, y_train.values.ravel()) #fitting\n",
    "y_pred= random_forest1.predict(X_test)  #predicting\n",
    "print(\"Target score - \" + str(metrics.accuracy_score(y_test, y_pred)) )#model score for target vaiable\n",
    "print(confusion_matrix(y_test, y_pred)) #the confusion matrix\n",
    "print(classification_report(y_test, y_pred)) #the classification report\n",
    " \n",
    "print(\"Signal  - \"+str(sum(y_train[\"target_variable\"])) +\" bought it out of \"+str(len(y_train))+\" in train dataset\")\n",
    "print(\"Signal  - \"+str(sum(y_test[\"target_variable\"])) +\" bought it out of \"+str(len(y_test))+\" in test dataset\")\n",
    " \n",
    "print(dataset[cols].corr()) #correlation values\n",
    " \n",
    "#another model - with XGBoost package\n",
    "xgb_model1 = XGBClassifier()\n",
    "xgb_model1.fit(X_train, y_train.values.ravel())\n",
    "y_pred = xgb_model1.predict(X_test) # make predictions for test data\n",
    "accuracy = accuracy_score(y_test, y_pred) #accuracy score\n",
    "print(\"Target score - \" + str(accuracy)+\" for XGBoost model\" )#model score for target vaiable\n",
    "print(confusion_matrix(y_test, y_pred)) #the confusion matrix\n",
    "print(classification_report(y_test, y_pred))#the classification report\n",
    " \n",
    "#ROC AUC curve for random forest model and for XGBoost model - together\n",
    "y_pred_prob = random_forest1.predict_proba(X_test)[:,1]  # Compute predicted probabilities: y_pred_prob\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob) # Generate ROC curve values: fpr, tpr, thresholds RF\n",
    "y_pred_prob1 = xgb_model1.predict_proba(X_test)[:,1]  # Compute predicted probabilities: y_pred_prob\n",
    "fpr1, tpr1, thresholds1 = roc_curve(y_test, y_pred_prob1) # Generate ROC curve values: fpr, tpr, thresholds XGB\n",
    "# Plot ROC curve\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr, tpr, color='red')\n",
    "plt.plot(fpr1, tpr1, color='blue')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves (red for Random Forest, blue for XGBoost)')\n",
    "plt.show()\n",
    " \n",
    "plt.matshow(dataset[cols].corr()) #the correlation matrix of features\n",
    " \n",
    "#Cross validation for random forest \n",
    "cv_scores_rd10 = cross_val_score(random_forest1,dataset[cols],dataset[target],cv=10) \n",
    "print(\"Average 10-Fold CV Score for random forest: {}\".format(np.mean(cv_scores_rd10)))\n",
    "cv_scores_rd20 = cross_val_score(random_forest1,dataset[cols],dataset[target],cv=20) \n",
    "print(\"Average 20-Fold CV Score for random forest: {}\".format(np.mean(cv_scores_rd20)))\n",
    "cv_scores_rd30 = cross_val_score(random_forest1,dataset[cols],dataset[target],cv=30) \n",
    "print(\"Average 30-Fold CV Score for random forest: {}\".format(np.mean(cv_scores_rd30)))\n",
    " \n",
    "#Cross validation for XGBoost\n",
    "cv_scores_xgb10 = cross_val_score(xgb_model1,dataset[cols],dataset[target],cv=10) \n",
    "print(\"Average 10-Fold CV Score for XGBoost: {}\".format(np.mean(cv_scores_xgb10)))\n",
    "cv_scores_xgb20 = cross_val_score(xgb_model1,dataset[cols],dataset[target],cv=20) \n",
    "print(\"Average 20-Fold CV Score for XGBoost: {}\".format(np.mean(cv_scores_xgb20)))\n",
    "cv_scores_xgb30 = cross_val_score(xgb_model1,dataset[cols],dataset[target],cv=30) \n",
    "print(\"Average 30-Fold CV Score for XGBoost: {}\".format(np.mean(cv_scores_xgb30)))\n",
    "#importances of features and graph of them (horizontal barplot)\n",
    "importances1 = random_forest1.feature_importances_\n",
    "indices1 = np.argsort(importances1)\n",
    "plt.title('Random forest feature importances')\n",
    "plt.barh(range(14), importances1[indices1], color='blue')\n",
    "plt.yticks(range(14), cols)\n",
    "plt.show()\n",
    " \n",
    "importances1 = xgb_model1.feature_importances_\n",
    "indices1 = np.argsort(importances1)\n",
    "plt.title('XGB feature importances')\n",
    "plt.barh(range(14), importances1[indices1], color='blue')\n",
    "plt.yticks(range(14), cols)\n",
    "plt.show()\n",
    "\n",
    "#feature importances consecutively \n",
    "cols2=['numerical_feature1',\n",
    "      'numerical_feature2',\n",
    "      'numerical_feature3',\n",
    "      'category_feature1',\n",
    "      'category_feature2',\n",
    "      'category_feature3',\n",
    "      'category_feature4',\n",
    "      'numerical_feature4',\n",
    "      'numerical_feature5',\n",
    "      'numerical_feature6',\n",
    "      'numerical_feature7',\n",
    "      'numerical_feature8',\n",
    "      'numerical_feature9',\n",
    "      'numerical_feature10']\n",
    "random_forest2 = RandomForestClassifier()\n",
    "random_forest2.fit(dataset[cols2], dataset[target]) #fitting\n",
    "importances1 = random_forest2.feature_importances_\n",
    "indices1 = np.argsort(importances1)\n",
    "plt.barh(range(14), importances1[indices1], color='blue')\n",
    "plt.yticks(range(14), cols2)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
